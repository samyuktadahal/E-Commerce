import pyodbc

conn = pyodbc.connect(
    r'DRIVER={ODBC Driver 17 for SQL Server};'
    r'SERVER=Samyukta\LOCALHOST;'
    r'DATABASE=Ecommerce;'
    r'Trusted_Connection=yes;'
)

print("✅ Connection successful!")


import pandas as pd
import pyodbc
import os

# List of CSV files and corresponding table names
csv_files = [
    ('customers.csv', 'customers'),
    ('orders.csv', 'orders'),
    ('sellers.csv', 'sellers'),
    ('products.csv', 'products'),
    ('geolocation.csv', 'geolocation'),
    ('payments.csv', 'payments'),
    ('order_items.csv', 'order_items')
]

# Connect to SQL Server using Windows Authentication
conn = pyodbc.connect(
    r'DRIVER={ODBC Driver 17 for SQL Server};'
    r'SERVER=Samyukta\LOCALHOST;'
    r'DATABASE=ecommerce;'
    r'Trusted_Connection=yes;'
)
cursor = conn.cursor()

# Folder containing the CSV files
folder_path = 'C:/Users/ASUS/OneDrive/Desktop/ECommerce'

# Function to map pandas dtypes to SQL Server types
def get_sql_type(dtype):
    if pd.api.types.is_integer_dtype(dtype):
        return 'INT'
    elif pd.api.types.is_float_dtype(dtype):
        return 'FLOAT'
    elif pd.api.types.is_bool_dtype(dtype):
        return 'BIT'
    elif pd.api.types.is_datetime64_any_dtype(dtype):
        return 'DATETIME'
    else:
        return 'NVARCHAR(MAX)'

# Loop over each CSV file
for csv_file, table_name in csv_files:
    file_path = os.path.join(folder_path, csv_file)
    
    df = pd.read_csv(file_path)
    df = df.where(pd.notnull(df), None)  # Replace NaN with None

    print(f"Processing {csv_file} ({len(df)} rows)")

    # Clean column names
    df.columns = [col.strip().replace(' ', '_').replace('-', '_').replace('.', '_') for col in df.columns]

    # Create table if it doesn't exist
    columns = ', '.join([f'[{col}] {get_sql_type(df[col].dtype)}' for col in df.columns])
    create_table_query = f'IF OBJECT_ID(N\'{table_name}\', N\'U\') IS NULL CREATE TABLE {table_name} ({columns})'
    cursor.execute(create_table_query)

    # Insert data
    placeholders = ', '.join(['?'] * len(df.columns))
    column_names = ', '.join([f'[{col}]' for col in df.columns])
    insert_query = f'INSERT INTO {table_name} ({column_names}) VALUES ({placeholders})'

    for _, row in df.iterrows():
        values = tuple(None if pd.isna(x) else x for x in row)
        cursor.execute(insert_query, values)

    conn.commit()
    print(f"✅ {table_name} imported successfully.\n")

# Close connection
conn.close()
